{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE EXPLORATÓRIA, LIMPEZA E TRANFORMAÇÃO - PARTE 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALAÇÃO E CARREGAMENTO DOS PACOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os pacotes \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-talk')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "df = pd.read_csv('dataset.csv', sep = ',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as observações contendo Ano\n",
    "df_idx= df[df[\"Ano\"]<=1989].index\n",
    "df= df.drop(df_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando as variáveis Ano, Cilindros, Volume_Motor e Airbag para object\n",
    "df['Ano'] = df['Ano'].astype(str)\n",
    "df['Portas'] = df['Portas'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma cópia do dataframne\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo\n",
    "print(\"Linhas: \", df1.shape[0])\n",
    "print(\"Colunas: \", df1.shape[1])\n",
    "print(\"\\nVariáveis: \\n\", df1.columns.tolist())\n",
    "print(\"\\nValores Ausentes: \\n\" , df1.isnull().sum())\n",
    "print(\"\\nValores Únicos: \\n\", df1.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas numéricas (quantitativas)\n",
    "colunas_numericas = ['Preco_Seguro', 'Volume_Motor','Quilometragem','Cilindros', 'Airbag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas categóricas\n",
    "colunas_categoricas = ['Fabricante', 'Modelo', 'Ano', 'Categoria', 'Interior_Couro', 'Tipo_Combustivel', 'Tipo_Cambio', 'Tracao_Rodas', 'Portas', 'Rodas', 'Cor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se o total de variáveis está coberto nos objetos anteriores\n",
    "len(colunas_numericas) + len(colunas_categoricas) == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes com os tipos diferentes de variáveis\n",
    "df_num = df1[colunas_numericas]\n",
    "df_cat = df1[colunas_categoricas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico das variáveis numéricas\n",
    "sumario_num = pd.DataFrame(index = df_num.columns)\n",
    "sumario_num['Tipo de Dado'] = df_num.dtypes.values\n",
    "sumario_num['Registros Não Nulos'] = df_num.count().values\n",
    "sumario_num['Registros Não Zero'] = df_num.astype(bool).sum(axis = 0)\n",
    "sumario_num['% Populado'] = round(sumario_num['Registros Não Nulos'] / df_num.shape[0]*100,2)\n",
    "sumario_num['Valores Únicos'] = df_num.nunique().values\n",
    "sumario_num['Min'] = round(df_num.min(),2)\n",
    "sumario_num['Max'] = round(df_num.max(),2)\n",
    "sumario_num['Mean'] = round(df_num.mean(),2)\n",
    "sumario_num['Std'] = round(df_num.std(),2)\n",
    "\n",
    "sumario_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico das variáveis categóricas\n",
    "sumario_cat = pd.DataFrame(index = df_cat.columns)\n",
    "sumario_cat['Tipo de Dado'] = df_cat.dtypes.values\n",
    "sumario_cat['Registros Não Nulos'] = df_cat.count().values\n",
    "sumario_cat['% Populado'] = round(sumario_cat['Registros Não Nulos'] / df_cat.shape[0]*100,2)\n",
    "sumario_cat['# Valores Únicos'] = df_cat.nunique().values\n",
    "\n",
    "# Adiciona mais uma coluna com valores mais comuns\n",
    "temp = []\n",
    "for coluna in colunas_categoricas:\n",
    "    temp.append(df_cat[coluna].value_counts().idxmax())\n",
    "sumario_cat['Valores Mais Comuns'] = temp\n",
    "sumario_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 1 - Preco_Convenio\n",
    "df1['Preco_Seguro'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 2 - Fabricante\n",
    "fabricante = df1['Fabricante'].value_counts().rename_axis('Fabricante').reset_index(name = 'Total')\n",
    "fabricante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 3 - Modelo\n",
    "modelo = df1['Modelo'].value_counts().rename_axis('Modelo').reset_index(name = 'Total')\n",
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 4 - Ano\n",
    "ano = df1['Ano'].value_counts().rename_axis('Ano').reset_index(name = 'Total')\n",
    "ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 5 - Categoria\n",
    "categoria = df1['Categoria'].value_counts().rename_axis('Categoria').reset_index(name = 'Total')\n",
    "categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 6 - Interior_Couro\n",
    "interior_couro = df1['Interior_Couro'].value_counts().rename_axis('Interior_Couro').reset_index(name = 'Total')\n",
    "interior_couro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 7 - Tipo_Combustivel\n",
    "tipo_combustivel = df1['Tipo_Combustivel'].value_counts().rename_axis('Tipo_Combustivel').reset_index(name = 'Total')\n",
    "tipo_combustivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 8 - Volume_Motor\n",
    "df1['Volume_Motor'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 9 - Quilometragem\n",
    "df1['Quilometragem'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 10 - Cilindros\n",
    "df1['Cilindros'].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 11 - Tipo_Cambio\n",
    "tipo_cambio = df1['Tipo_Cambio'].value_counts().rename_axis('Tipo_Cambio').reset_index(name = 'Total')\n",
    "tipo_cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 12 - Tracao_Rodas\n",
    "tracao_rodas = df1['Tracao_Rodas'].value_counts().rename_axis('Tracao_Rodas').reset_index(name = 'Total')\n",
    "tracao_rodas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 13 - Portas\n",
    "portas = df1['Portas'].value_counts().rename_axis('Portas').reset_index(name = 'Total')\n",
    "portas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 14 - Rodas\n",
    "rodas = df1['Rodas'].value_counts().rename_axis('Rodas').reset_index(name = 'Total')\n",
    "rodas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 15 - Cor\n",
    "cor = df1['Cor'].value_counts().rename_axis('Cor').reset_index(name = 'Total')\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável 16 - Airbag\n",
    "airbag = df1['Airbag'].value_counts().rename_axis('Airbag').reset_index(name = 'Total')\n",
    "airbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o encoder para variáveis categóricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# Aplica o encoder nas variáveis que estão com string\n",
    "df2['Fabricante'] = lb.fit_transform(df2['Fabricante'])\n",
    "df2['Modelo'] = lb.fit_transform(df2['Modelo'])\n",
    "df2['Interior_Couro'] = lb.fit_transform(df2['Interior_Couro'])\n",
    "df2['Tipo_Combustivel'] = lb.fit_transform(df2['Tipo_Combustivel'])\n",
    "df2['Tipo_Cambio'] = lb.fit_transform(df2['Tipo_Cambio'])\n",
    "df2['Tracao_Rodas'] = lb.fit_transform(df2['Tracao_Rodas'])\n",
    "df2['Portas'] = lb.fit_transform(df2['Portas'])\n",
    "df2['Rodas'] = lb.fit_transform(df2['Rodas'])\n",
    "df2['Ano'] = lb.fit_transform(df2['Ano'])\n",
    "df2['Categoria'] = lb.fit_transform(df2['Categoria'])\n",
    "df2['Cor'] = lb.fit_transform(df2['Cor'])\n",
    "\n",
    "# Remove valores missing eventualmente gerados\n",
    "df2.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Correlação \n",
    "corr = df2.corr().stack().reset_index(name=\"correlation\")\n",
    "\n",
    "sns.set_theme(style = 'whitegrid', font='sans-serif', font_scale=1)\n",
    "plt.figure(figsize = (10, 10))\n",
    "fig1 = sns.relplot(data=corr, x=\"level_0\", y=\"level_1\", hue=\"correlation\", size=\"correlation\",\n",
    "                    palette=\"vlag\", hue_norm=(-1, 1), edgecolor=\".8\", height=10, sizes=(150, 300))\n",
    "plt.title(\"Matriz de Correlação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação\n",
    "df2.corr()[\"Preco_Seguro\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELEÇÃO DE VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma cópia do dataframne e removendo a coluna Id\n",
    "df3 = df2.copy()\n",
    "df3.drop(columns=[\"Fabricante\", 'Tipo_Combustivel', 'Tipo_Cambio', 'Tracao_Rodas', 'Portas', 'Rodas', \n",
    "                  'Interior_Couro'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARAÇÃO DOS DADOS (PRÉ-PROCESSAMENTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZAÇÃO - Transformando os dados para a mesma escala (entre 0 e 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "dados_norm = df3.values\n",
    "x_norm = dados_norm[:,1:9]\n",
    "y = dados[:,0]\n",
    "\n",
    "# Gerando a nova escala (normalizando os dados)\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "dados_normalizados = scaler.fit_transform(x_norm)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df3.values)\n",
    "print(\"\\nDados Normalizados: \\n\\n\", dados_normalizados[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADRONIZAÇÃO - Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "dados = df3.values\n",
    "x_padr = dados[:,1:9]\n",
    "y = dados[:,0]\n",
    "\n",
    "# Gerando o novo padrão\n",
    "scaler = StandardScaler().fit(x_padr)\n",
    "dados_padronizados = scaler.transform(x_padr)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df3.values)\n",
    "print(\"\\nDados Padronizados: \\n\\n\", dados_padronizados[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELAGEM PREDITIVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados ORIGINAIS em conjuntos de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "dados = df3.values\n",
    "x = dados[:,1:9]\n",
    "y = dados[:,0]\n",
    "\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.30)\n",
    "print(x_treino.shape, y_treino.shape, x_teste.shape, y_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos  dados Originais\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modelo_v1 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v1.fit(x_treino, y_treino)\n",
    "modelo_v1.score(x_treino, y_treino)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v1 = modelo_v1.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v1 nos dados de teste\n",
    "v1_acuracia = modelo_v1.score(x_teste, y_teste)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v1_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo utilizando o CROSS VALIDATION\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definindo os valores para os folds\n",
    "num_folds = 100\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_CV1 = modelo_v1\n",
    "resultado_v1 = cross_val_score(modelo_CV1, x_treino, y_treino, cv = kfold)\n",
    "\n",
    "# Usamos a média e o desvio padrão\n",
    "print(\"Acurácia Final: %.2f%%\" % (resultado_v1.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados para o dataframe de comparação dos modelos\n",
    "acuracia_v1 = (v1_acuracia * 100.0).round(3)\n",
    "\n",
    "# Dicionário de métricas e metadados do modelo_v1\n",
    "\n",
    "RFR_dict_v1 = {'Modelo':'Random Forest Regressor',\n",
    "               'Versão':'1',\n",
    "               'Dados':'Originais',\n",
    "              'Acuracia': acuracia_v1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados NORMALIZADOS em conjuntos de treino e teste\n",
    "\n",
    "x_treino1, x_teste1, y_treino1, y_teste1 = train_test_split(dados_normalizados, y, test_size = 0.30)\n",
    "print(x_treino1.shape, y_treino1.shape, x_teste1.shape, y_teste1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados Normalizados\n",
    "\n",
    "modelo_v2 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v2.fit(x_treino1, y_treino1)\n",
    "modelo_v2.score(x_treino1, y_treino1)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v2 = modelo_v2.predict(x_teste1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v1 nos dados de teste\n",
    "v2_acuracia = modelo_v2.score(x_teste1, y_teste1)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v2_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados para o dataframe de comparação dos modelos\n",
    "acuracia_v2 = (v2_acuracia * 100.0).round(3)\n",
    "\n",
    "# Dicionário de métricas e metadados do modelo_v2\n",
    "\n",
    "RFR_dict_v2 = {'Modelo':'Random Forest Regressor',\n",
    "               'Versão':'2',\n",
    "               'Dados':'Normalizados',\n",
    "              'Acuracia': acuracia_v2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados PADRONIZADOS em conjuntos de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_treino2, x_teste2, y_treino2, y_teste2 = train_test_split(dados_padronizados, y, test_size = 0.30)\n",
    "print(x_treino2.shape, y_treino2.shape, x_teste2.shape, y_teste2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos dados PADRONIZADOS\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modelo_v3 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v3.fit(x_treino2, y_treino2)\n",
    "modelo_v3.score(x_treino2, y_treino2)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v3 = modelo_v3.predict(x_teste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v1 nos dados de teste\n",
    "v3_acuracia = modelo_v3.score(x_teste2, y_teste2)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v3_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados para o dataframe de comparação dos modelos\n",
    "acuracia_v3 = (v3_acuracia * 100.0).round(3)\n",
    "\n",
    "# Dicionário de métricas e metadados do modelo_v3\n",
    "\n",
    "RFR_dict_v3 = {'Modelo':'Random Forest Regressor',\n",
    "               'Versão':'3',\n",
    "               'Dados':'Padronizados',\n",
    "              'Acuracia': acuracia_v3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARAÇÃO ENTRE OS MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena todos os dicionários em um dataframe\n",
    "resumo = pd.DataFrame({'Modelo_v1':pd.Series(RFR_dict_v1),\n",
    "                       'Modelo_v2':pd.Series(RFR_dict_v2),\n",
    "                       'Modelo_v3':pd.Series(RFR_dict_v3)\n",
    "                     })\n",
    "resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTIMIZAÇÃO DO MODELO SELECIONADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AJUSTES DE HIPERPARÂMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM SEARCH PARAMETER TUNING\n",
    "# Este método gera amostras dos parâmetros dos algoritmos a partir de uma distribuição randômica uniforme para um número fixo\n",
    "# de iterações. Um modelo é construído e testado para cada combinação de parâmetros.\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "modelo_hp = RandomForestRegressor()\n",
    "x_treino_final = x_treino\n",
    "y_treino_final = y_treino\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "iteracoes = 50\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_grid = {'n_estimators': [100, 150, 200, 250], 'criterion': ['mse', 'mae'], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "# Criando o grid\n",
    "rsearch = RandomizedSearchCV(estimator = modelo_hp, \n",
    "                             param_distributions = valores_grid, \n",
    "                             n_iter = iteracoes)\n",
    "rsearch.fit(x_treino_final, y_treino_final)\n",
    "\n",
    "# Print dos resultados\n",
    "print(\"Acurácia: %.2f\" % (rsearch.best_score_ * 100))\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", rsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGENHARIA DE ATRIBUTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma cópia do dataframe e inserindo a coluna total\n",
    "df4= df1.copy()\n",
    "df4 = pd.merge(df4, modelo, on = 'Modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as colunas\n",
    "df4.drop(columns=[\"Fabricante\", 'Tipo_Combustivel', 'Tipo_Cambio', 'Tracao_Rodas', 'Portas', 'Rodas', \n",
    "                  'Interior_Couro'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a categoria Outros na variável Modelo\n",
    "\n",
    "for item in range(0,len(df4['Modelo']),1):\n",
    "   \n",
    "    if int(df4['Total'][item]) <=1:\n",
    "        df4['Modelo'][item]= 'OUTROS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[(df4['Modelo']) == 'OUTROS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2 = df4['Modelo'].value_counts().rename_axis('Modelo').reset_index(name = 'Total')\n",
    "modelo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.drop(columns=['Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravando o dataframe utilizado no modelo final antes do encoder\n",
    "df4.to_csv('dataset_final.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o encoder para variáveis categóricas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# Aplica o encoder nas variáveis que estão com string\n",
    "df4['Modelo'] = lb.fit_transform(df4['Modelo'])\n",
    "df4['Ano'] = lb.fit_transform(df4['Ano'])\n",
    "df4['Categoria'] = lb.fit_transform(df4['Categoria'])\n",
    "df4['Cor'] = lb.fit_transform(df4['Cor'])\n",
    "\n",
    "# Remove valores missing eventualmente gerados\n",
    "df4.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação\n",
    "df4.corr()[\"Preco_Seguro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados ORIGINAIS em conjuntos de treino e teste\n",
    "\n",
    "# Separando o array em componentes de input (X) e output (Y)\n",
    "dados2 = df4.values\n",
    "x2 = dados[:,1:9]\n",
    "y2 = dados[:,0]\n",
    "\n",
    "x_treino3, x_teste3, y_treino3, y_teste3 = train_test_split(x2, y2, test_size = 0.30)\n",
    "print(x_treino3.shape, y_treino3.shape, x_teste3.shape, y_teste3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto de RANDOM FOREST - Utilização dos  dados Originais\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modelo_v4 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo com dados de treino e checando o score\n",
    "modelo_v4.fit(x_treino3, y_treino3)\n",
    "modelo_v4.score(x_treino3, y_treino3)\n",
    "\n",
    "# Previsões\n",
    "valores_previstos_v4 = modelo_v4.predict(x_teste3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo_v1 nos dados de teste\n",
    "v4_acuracia = modelo_v4.score(x_teste3, y_teste3)\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (v4_acuracia * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo utilizando o CROSS VALIDATION\n",
    "\n",
    "# Definindo os valores para os folds\n",
    "num_folds = 100\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_CV4 = modelo_v4\n",
    "resultado_v4 = cross_val_score(modelo_CV4, x_treino3, y_treino3, cv = kfold)\n",
    "\n",
    "# Usamos a média e o desvio padrão\n",
    "print(\"Acurácia Final: %.2f%%\" % (resultado_v4.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados para o dataframe de comparação dos modelos\n",
    "acuracia_v4 = (v4_acuracia * 100.0).round(3)\n",
    "\n",
    "# Dicionário de métricas e metadados do modelo_v4\n",
    "\n",
    "RFR_dict_v4 = {'Modelo':'Random Forest Regressor',\n",
    "               'Versão':'4',\n",
    "               'Dados':'Originais',\n",
    "              'Acuracia': acuracia_v4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena todos os dicionários em um dataframe\n",
    "resumo = pd.DataFrame({'Modelo_v1':pd.Series(RFR_dict_v1),\n",
    "                       'Modelo_v2':pd.Series(RFR_dict_v2),\n",
    "                       'Modelo_v3':pd.Series(RFR_dict_v3),\n",
    "                       'Modelo_v4':pd.Series(RFR_dict_v4)\n",
    "                     })\n",
    "resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando o dataframe para o streamlit\n",
    "df5 = pd.read_csv('dataset_final.csv', sep = ',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.merge(\n",
    "        df4, how=\"inner\", left_index=True, right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravando o dataframe para utilização no streamlit\n",
    "df5.to_csv('dataset_st.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREVISÃO COM O MODELO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produz a matriz com os novos dados de entrada para a previsão\n",
    "Modelo = 438\n",
    "Ano = 22\n",
    "Categoria = 4\n",
    "Volume_Motor = 35\n",
    "Quilometragem = 97000\n",
    "Cilindros = 6\n",
    "Cor = 10\n",
    "Airbag = 12\n",
    "\n",
    "\n",
    "# Lista com os valores das variáveis\n",
    "dados_novo_cliente = [Modelo, Ano, Categoria, Volume_Motor, Quilometragem, Cilindros, Cor, Airbag]\n",
    "\n",
    "# Reshape\n",
    "novo_cliente = np.array(dados_novo_cliente).reshape(1, -1)\n",
    "\n",
    "# Previsão\n",
    "print(\"Preço previsto para o Convênio: R$ %.2f\" % (modelo_v4.predict(novo_cliente)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVANDO O MELHOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvando o modelo\n",
    "arquivo = 'MODELO_FINAL.sav'\n",
    "pickle.dump(modelo_v4, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o arquivo\n",
    "modelo = pickle.load(open(arquivo, 'rb'))\n",
    "modelo_prod = modelo_v4.score(x_teste3, y_teste3)\n",
    "print(\"Modelo carregado!\")\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia nos Dados de Teste: %.2f%%\" % (modelo_prod * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
